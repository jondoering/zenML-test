{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.core.datasources.csv_datasource import CSVDatasource\n",
    "from zenml.core.pipelines.training_pipeline import TrainingPipeline\n",
    "from zenml.core.steps.evaluator.tfma_evaluator import TFMAEvaluator\n",
    "from zenml.core.steps.split.random_split import RandomSplit\n",
    "from zenml.core.steps.preprocesser.standard_preprocesser.standard_preprocesser import StandardPreprocesser\n",
    "from zenml.core.steps.trainer.tensorflow_trainers.tf_ff_trainer import FeedForwardTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:32:51,400 — zenml.core.pipelines.base_pipeline — INFO — Pipeline Quickstart created.\n"
     ]
    }
   ],
   "source": [
    "training_pipeline = TrainingPipeline(name='Quickstart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:32:56,135 — zenml.core.datasources.base_datasource — INFO — Datasource Pima Indians Diabetes Dataset created.\n"
     ]
    }
   ],
   "source": [
    "# Add a datasource. This will automatically track and version it.\n",
    "ds = CSVDatasource(name='Pima Indians Diabetes Dataset', \n",
    "                   path='gs://zenml_quickstart/diabetes.csv')\n",
    "training_pipeline.add_datasource(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a random 70/30 train-eval split\n",
    "training_pipeline.add_split(RandomSplit(split_map={'train': 0.7, 'eval': 0.3}))\n",
    "\n",
    "# StandardPreprocesser() has sane defaults for normal preprocessing methods\n",
    "training_pipeline.add_preprocesser(\n",
    "    StandardPreprocesser(\n",
    "        features=['times_pregnant', 'pgc', 'dbp', 'tst', 'insulin', 'bmi',\n",
    "                  'pedigree', 'age'],\n",
    "        labels=['has_diabetes'],\n",
    "        overwrite={'has_diabetes': {\n",
    "            'transform': [{'method': 'no_transform', 'parameters': {}}]}}\n",
    "    ))\n",
    "\n",
    "# Add a trainer\n",
    "training_pipeline.add_trainer(FeedForwardTrainer(\n",
    "    loss='binary_crossentropy',\n",
    "    last_activation='sigmoid',\n",
    "    output_units=1,\n",
    "    metrics=['accuracy'],\n",
    "    epochs=20))\n",
    "\n",
    "\n",
    "# Add an evaluator\n",
    "training_pipeline.add_evaluator(\n",
    "    TFMAEvaluator(slices=[['has_diabetes']],\n",
    "                  metrics={'has_diabetes': ['binary_crossentropy',\n",
    "                                            'binary_accuracy']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:13,713 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component DataGen is running.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:13,767 — apache_beam.runners.interactive.interactive_environment — WARNING — Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:14,003 — zenml.core.steps.data.csv_data_step — INFO — Matched 1: ['gs://zenml_quickstart/diabetes.csv']\n",
      "2021-02-04 17:33:14,005 — zenml.core.steps.data.csv_data_step — INFO — Using header from file: gs://zenml_quickstart/diabetes.csv.\n",
      "2021-02-04 17:33:14,251 — zenml.core.steps.data.csv_data_step — INFO — Header: ['times_pregnant', 'pgc', 'dbp', 'tst', 'insulin', 'bmi', 'pedigree', 'age', 'has_diabetes'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:17,257 — apache_beam.internal.gcp.auth — WARNING — Unable to find default credentials to use: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.\n",
      "Connecting anonymously.\n",
      "2021-02-04 17:33:18,661 — apache_beam.io.tfrecordio — WARNING — Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:18,748 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component DataGen is finished.\n",
      "2021-02-04 17:33:18,750 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component DataStatistics is running.\n",
      "2021-02-04 17:33:19,815 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component DataStatistics is finished.\n",
      "2021-02-04 17:33:19,815 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component DataSchema is running.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:19,829 — tensorflow — WARNING — From /anaconda3/envs/zenml/lib/python3.8/site-packages/tensorflow_data_validation/utils/stats_util.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:19,843 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component DataSchema is finished.\n",
      "2021-02-04 17:33:19,844 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component SplitGen is running.\n",
      "2021-02-04 17:33:20,344 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component SplitGen is finished.\n",
      "2021-02-04 17:33:20,345 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component SplitStatistics is running.\n",
      "2021-02-04 17:33:22,145 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component SplitStatistics is finished.\n",
      "2021-02-04 17:33:22,146 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component SplitSchema is running.\n",
      "2021-02-04 17:33:22,164 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component SplitSchema is finished.\n",
      "2021-02-04 17:33:22,164 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component Transform is running.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:22,184 — tensorflow — WARNING — From /anaconda3/envs/zenml/lib/python3.8/site-packages/tfx/components/transform/executor.py:528: Schema (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Schema is a deprecated, use schema_utils.schema_from_feature_spec to create a `Schema`\n",
      "2021-02-04 17:33:22,339 — tensorflow — WARNING — From /anaconda3/envs/zenml/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:250: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "2021-02-04 17:33:22,702 — tensorflow — WARNING — TFT beam APIs accept both the TFXIO format and the instance dict format now. There is no need to set use_tfxio any more and it will be removed soon.\n",
      "2021-02-04 17:33:22,723 — root — WARNING — This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]] instead.\n",
      "2021-02-04 17:33:23,195 — root — WARNING — This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]] instead.\n",
      "2021-02-04 17:33:23,237 — tensorflow — WARNING — Tensorflow version (2.3.2) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "2021-02-04 17:33:23,494 — tensorflow — WARNING — From /anaconda3/envs/zenml/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:200: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "2021-02-04 17:33:23,513 — tensorflow — WARNING — Issue encountered when serializing tft_analyzer_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "2021-02-04 17:33:23,514 — tensorflow — WARNING — Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "2021-02-04 17:33:24,190 — tensorflow — WARNING — Issue encountered when serializing tft_analyzer_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "2021-02-04 17:33:24,191 — tensorflow — WARNING — Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "2021-02-04 17:33:24,788 — tensorflow — WARNING — Issue encountered when serializing tft_analyzer_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "2021-02-04 17:33:24,789 — tensorflow — WARNING — Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "2021-02-04 17:33:25,545 — tensorflow — WARNING — Tensorflow version (2.3.2) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "2021-02-04 17:33:25,580 — apache_beam.typehints.typehints — WARNING — Ignoring send_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,580 — apache_beam.typehints.typehints — WARNING — Ignoring return_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,581 — apache_beam.typehints.typehints — WARNING — Ignoring send_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,582 — apache_beam.typehints.typehints — WARNING — Ignoring return_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,584 — apache_beam.typehints.typehints — WARNING — Ignoring send_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,585 — apache_beam.typehints.typehints — WARNING — Ignoring return_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,629 — tensorflow — WARNING — Tensorflow version (2.3.2) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "2021-02-04 17:33:25,663 — apache_beam.typehints.typehints — WARNING — Ignoring send_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,664 — apache_beam.typehints.typehints — WARNING — Ignoring return_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,664 — apache_beam.typehints.typehints — WARNING — Ignoring send_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,665 — apache_beam.typehints.typehints — WARNING — Ignoring return_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,667 — apache_beam.typehints.typehints — WARNING — Ignoring send_type hint: <class 'NoneType'>\n",
      "2021-02-04 17:33:25,668 — apache_beam.typehints.typehints — WARNING — Ignoring return_type hint: <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:31,252 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component Transform is finished.\n",
      "2021-02-04 17:33:31,253 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component Trainer is running.\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "age_xf (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bmi_xf (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dbp_xf (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "insulin_xf (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pedigree_xf (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pgc_xf (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "times_pregnant_xf (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tst_xf (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8)            0           age_xf[0][0]                     \n",
      "                                                                 bmi_xf[0][0]                     \n",
      "                                                                 dbp_xf[0][0]                     \n",
      "                                                                 insulin_xf[0][0]                 \n",
      "                                                                 pedigree_xf[0][0]                \n",
      "                                                                 pgc_xf[0][0]                     \n",
      "                                                                 times_pregnant_xf[0][0]          \n",
      "                                                                 tst_xf[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           90          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "has_diabetes (Dense)            (None, 1)            11          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "      1/Unknown - 0s 84us/step - loss: 1.0908 - accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:31,835 — tensorflow — WARNING — From /anaconda3/envs/zenml/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "2021-02-04 17:33:31,858 — tensorflow — WARNING — Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0242s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 3ms/step - loss: 1.0004 - accuracy: 0.4062 - val_loss: 0.8287 - val_accuracy: 0.5139\n",
      "Epoch 2/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.8413 - accuracy: 0.5147 - val_loss: 0.7275 - val_accuracy: 0.5972\n",
      "Epoch 3/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.7257 - accuracy: 0.5993 - val_loss: 0.6607 - val_accuracy: 0.6389\n",
      "Epoch 4/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.6305 - val_loss: 0.6214 - val_accuracy: 0.6435\n",
      "Epoch 5/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.6875 - val_loss: 0.5825 - val_accuracy: 0.6944\n",
      "Epoch 6/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.7004 - val_loss: 0.5667 - val_accuracy: 0.6991\n",
      "Epoch 7/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.6985 - val_loss: 0.5479 - val_accuracy: 0.7083\n",
      "Epoch 8/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7096 - val_loss: 0.5301 - val_accuracy: 0.7315\n",
      "Epoch 9/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.7132 - val_loss: 0.5331 - val_accuracy: 0.7315\n",
      "Epoch 10/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.7243 - val_loss: 0.5242 - val_accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7316 - val_loss: 0.5251 - val_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7316 - val_loss: 0.5139 - val_accuracy: 0.7454\n",
      "Epoch 13/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7500 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7574 - val_loss: 0.5105 - val_accuracy: 0.7315\n",
      "Epoch 15/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7518 - val_loss: 0.5052 - val_accuracy: 0.7315\n",
      "Epoch 16/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7592 - val_loss: 0.5118 - val_accuracy: 0.7222\n",
      "Epoch 17/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7537 - val_loss: 0.5009 - val_accuracy: 0.7269\n",
      "Epoch 18/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7665 - val_loss: 0.5030 - val_accuracy: 0.7361\n",
      "Epoch 19/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7702 - val_loss: 0.5085 - val_accuracy: 0.7361\n",
      "Epoch 20/20\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7684 - val_loss: 0.4986 - val_accuracy: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:36,275 — tensorflow — WARNING — From /anaconda3/envs/zenml/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2021-02-04 17:33:36,283 — tensorflow — WARNING — From /anaconda3/envs/zenml/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:33:37,053 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component Trainer is finished.\n",
      "2021-02-04 17:33:37,054 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component Evaluator is running.\n",
      "2021-02-04 17:33:39,826 — zenml.core.backends.orchestrator.local.zenml_local_orchestrator — INFO — Component Evaluator is finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline locally\n",
    "training_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'age'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'bmi'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'dbp'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'has_diabetes'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'insulin'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'pedigree'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'pgc'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'times_pregnant'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'tst'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Type  Presence Valency Domain\n",
       "Feature name                                    \n",
       "'age'             FLOAT  required  single      -\n",
       "'bmi'             FLOAT  required  single      -\n",
       "'dbp'             FLOAT  required  single      -\n",
       "'has_diabetes'    FLOAT  required  single      -\n",
       "'insulin'         FLOAT  required  single      -\n",
       "'pedigree'        FLOAT  required  single      -\n",
       "'pgc'             FLOAT  required  single      -\n",
       "'times_pregnant'  FLOAT  required  single      -\n",
       "'tst'             FLOAT  required  single      -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See schema of data\n",
    "training_pipeline.view_schema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:34:03,734 — zenml.core.pipelines.training_pipeline — INFO — Viewing statistics. If magic=False then a new window will open up with a notebook for evaluation. If magic=True, then an attempt will be made to append to the current notebook.\n",
      "Launching server at http://localhost:58522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:34:04,275 — tornado.access — WARNING — 404 GET /favicon.ico (127.0.0.1) 0.36ms\n"
     ]
    }
   ],
   "source": [
    "# See statistics of train and eval\n",
    "training_pipeline.view_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 17:34:28,663 — zenml.core.pipelines.training_pipeline — INFO — Evaluating pipeline. If magic=False then a new window will open up with a notebook for evaluation. If magic=True, then an attempt will be made to append to the current notebook.\n"
     ]
    }
   ],
   "source": [
    "# Creates a notebook for evaluation\n",
    "training_pipeline.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenml",
   "language": "python",
   "name": "zenml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
